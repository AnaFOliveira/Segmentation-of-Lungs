{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(image, new_shape=[64,64,64]):\n",
    "    #Code adapted from Guido Zuidhof, available at: https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial\n",
    "    # Determine current pixel spacing\n",
    "\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    image = inter.zoom(image, real_resize_factor, mode='nearest')\n",
    "    \n",
    "    return image, new_spacing\n",
    "\n",
    "def read_image(in_file,image_shape=None, interpolation='linear', crop=None):\n",
    "    path = 'G:/CTimages/preprocessed/' \n",
    "    header_path = 'G:/CTimages/original/'\n",
    "    \n",
    "    patient_id = in_file.split(\"\\\\\")[0]\n",
    "    scan_path = header_path+patient_id+'/'\n",
    "    first_scan = os.listdir(scan_path)[0]\n",
    "    scan = pydicom.dcmread(scan_path+first_scan)\n",
    "                \n",
    "    image = fix_shape(image)\n",
    "    if crop:\n",
    "        image = crop_img_to_numpy_Version(image, previous_affine, crop, copy=True)\n",
    "    if image_shape:\n",
    "        return resize(image,previous_affine, scan, new_shape=image_shape, interpolation=interpolation)\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "def resize(image, previous_affine, scan, new_shape, interpolation=\"linear\"):\n",
    "    \"\"\"To change the size of the image, changes the spacing\"\"\"\n",
    "    \n",
    "    #image.header.get_zooms() representes the spacing. On dicom images, it's calculated by:\n",
    "    spacing =np.array([scan.SliceThickness,scan.PixelSpacing[0],scan.PixelSpacing[1]])    \n",
    "    image = reorder_img_to_Numpy(image, previous_affine,resample=interpolation)\n",
    "    zoom_level = np.divide(new_shape, image.shape)\n",
    "    new_spacing = np.divide(spacing, zoom_level)\n",
    "\n",
    "    new_data = resample_to_spacing(image, spacing, new_spacing,\n",
    "                                   interpolation=interpolation)\n",
    "    new_affine = np.copy(previous_affine)\n",
    "    np.fill_diagonal(new_affine, new_spacing.tolist() + [1])\n",
    "    new_affine[:3, 3] += calculate_origin_offset(new_spacing, spacing)\n",
    "    \n",
    "    return new_data,new_affine,new_spacing\n",
    "    \n",
    "def fix_shape(image):\n",
    "    if image.shape[-1] == 1:\n",
    "        return image.__class__(dataobj=np.squeeze(image.get_data()), affine=image.affine)\n",
    "    return image\n",
    "    \n",
    "def crop_img_to_numpy_Version(img, affine, slices, copy=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Code adapted from nibabel module, available at: https://github.com/nilearn/nilearn/blob/master/nilearn/image/image.py\n",
    "    \n",
    "    Crops image to a smaller size\n",
    "    Crop img to size indicated by slices and adjust affine\n",
    "    accordingly\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: Niimg-like object\n",
    "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "        Img to be cropped. If slices has less entries than img\n",
    "        has dimensions, the slices will be applied to the first len(slices)\n",
    "        dimensions\n",
    "    slices: list of slices\n",
    "        Defines the range of the crop.\n",
    "        E.g. [slice(20, 200), slice(40, 150), slice(0, 100)]\n",
    "        defines a 3D cube\n",
    "    copy: boolean\n",
    "        Specifies whether cropped data is to be copied or not.\n",
    "        Default: True\n",
    "    Returns\n",
    "    -------\n",
    "    cropped_img: Niimg-like object\n",
    "        See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "        Cropped version of the input image\n",
    "    \"\"\"\n",
    "\n",
    "    data = img.copy()\n",
    "\n",
    "    cropped_data = data[tuple(slices)]\n",
    "    if copy:\n",
    "        cropped_data = cropped_data.copy()\n",
    "\n",
    "    linear_part = affine[:3, :3]\n",
    "    old_origin = affine[:3, 3]\n",
    "    new_origin_voxel = np.array([s.start for s in slices])\n",
    "    new_origin = old_origin + linear_part.dot(new_origin_voxel)\n",
    "\n",
    "    new_affine = np.eye(4)\n",
    "    new_affine[:3, :3] = linear_part\n",
    "    new_affine[:3, 3] = new_origin\n",
    "\n",
    "    return cropped_data\n",
    "\n",
    "def reorder_img_to_Numpy(img,previous_affine, new_shape=(64,64,64),resample=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Code adapted from nilearn module, available at: https://github.com/nilearn/nilearn/blob/master/nilearn/image/resampling.py\n",
    "    Returns an image with the affine diagonal (by permuting axes).\n",
    "    The orientation of the new image will be RAS (Right, Anterior, Superior).\n",
    "    If it is impossible to get xyz ordering by permuting the axes, a\n",
    "    'ValueError' is raised.\n",
    "        Parameters\n",
    "        -----------\n",
    "        img: Niimg-like object\n",
    "            See http://nilearn.github.io/manipulating_images/input_output.html\n",
    "            Image to reorder.\n",
    "        resample: None or string in {'continuous', 'linear', 'nearest'}, optional\n",
    "            If resample is None (default), no resampling is performed, the\n",
    "            axes are only permuted.\n",
    "            Otherwise resampling is performed and 'resample' will\n",
    "            be passed as the 'interpolation' argument into\n",
    "            resample_img.\n",
    "    \"\"\"\n",
    "\n",
    "    affine = previous_affine.copy()\n",
    "    A, b = to_matrix_vector(affine)\n",
    "\n",
    "    if not np.all((np.abs(A) > 0.001).sum(axis=0) == 1):\n",
    "        # The affine is not nearly diagonal\n",
    "        if resample is None:\n",
    "            raise ValueError('Cannot reorder the axes: '\n",
    "                             'the image affine contains rotations')\n",
    "        else:\n",
    "            # Identify the voxel size using a QR decomposition of the\n",
    "            # affine\n",
    "            Q, R = np.linalg.qr(affine[:3, :3])\n",
    "            target_affine = np.diag(np.abs(np.diag(R))[\n",
    "                                                np.abs(Q).argmax(axis=1)])\n",
    "            return resample(img, new_shape)\n",
    "\n",
    "    axis_numbers = np.argmax(np.abs(A), axis=0)\n",
    "    data = img\n",
    "    while not np.all(np.sort(axis_numbers) == axis_numbers):\n",
    "        first_inversion = np.argmax(np.diff(axis_numbers)<0)\n",
    "        axis1 = first_inversion + 1\n",
    "        axis2 = first_inversion\n",
    "        data = np.swapaxes(data, axis1, axis2)\n",
    "        order = np.array((0, 1, 2, 3))\n",
    "        order[axis1] = axis2\n",
    "        order[axis2] = axis1\n",
    "        affine = affine.T[order].T\n",
    "        A, b = to_matrix_vector(affine)\n",
    "        axis_numbers = np.argmax(np.abs(A), axis=0)\n",
    "\n",
    "    # Now make sure the affine is positive\n",
    "    pixdim = np.diag(A).copy()\n",
    "    if pixdim[0] < 0:\n",
    "        b[0] = b[0] + pixdim[0]*(data.shape[0] - 1)\n",
    "        pixdim[0] = -pixdim[0]\n",
    "        slice1 = slice(None, None, -1)\n",
    "    else:\n",
    "        slice1 = slice(None, None, None)\n",
    "    if pixdim[1] < 0:\n",
    "        b[1] = b[1] + pixdim[1]*(data.shape[1] - 1)\n",
    "        pixdim[1] = -pixdim[1]\n",
    "        slice2 = slice(None, None, -1)\n",
    "    else:\n",
    "        slice2 = slice(None, None, None)\n",
    "    if pixdim[2] < 0:\n",
    "        b[2] = b[2] + pixdim[2]*(data.shape[2] - 1)\n",
    "        pixdim[2] = -pixdim[2]\n",
    "        slice3 = slice(None, None, -1)\n",
    "    else:\n",
    "        slice3 = slice(None, None, None)\n",
    "    data = data[slice1, slice2, slice3]\n",
    "    #affine = from_matrix_vector(np.diag(pixdim), b)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def pickle_dump(item, out_file):\n",
    "    with open(out_file, \"wb\") as opened_file:\n",
    "        pickle.dump(item, opened_file)\n",
    "\n",
    "\n",
    "def pickle_load(in_file):\n",
    "    with open(in_file, \"rb\") as opened_file:\n",
    "        return pickle.load(opened_file)\n",
    "\n",
    "\n",
    "def to_matrix_vector(transform):\n",
    "    \n",
    "    \"\"\"\n",
    "    Code from nilearn module, available at: https://github.com/nilearn/nilearn/blob/master/nilearn/image/resampling.py\n",
    "    Split an homogeneous transform into its matrix and vector components.\n",
    "    The transformation must be represented in homogeneous coordinates.\n",
    "    It is split into its linear transformation matrix and translation vector\n",
    "    components.\n",
    "    This function does not normalize the matrix. This means that for it to be\n",
    "    the inverse of from_matrix_vector, transform[-1, -1] must equal 1, and\n",
    "    transform[-1, :-1] must equal 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    transform: numpy.ndarray\n",
    "        Homogeneous transform matrix. Example: a (4, 4) transform representing\n",
    "        linear transformation and translation in 3 dimensions.\n",
    "    Returns\n",
    "    -------\n",
    "    matrix, vector: numpy.ndarray\n",
    "        The matrix and vector components of the transform matrix.  For\n",
    "        an (N, N) transform, matrix will be (N-1, N-1) and vector will be\n",
    "        a 1D array of shape (N-1,).\n",
    "    See Also\n",
    "    --------\n",
    "    from_matrix_vector\n",
    "    \"\"\"\n",
    "\n",
    "    ndimin = transform.shape[0] - 1\n",
    "    ndimout = transform.shape[1] - 1\n",
    "    matrix = transform[0:ndimin, 0:ndimout]\n",
    "    vector = transform[0:ndimin, ndimout]\n",
    "    return matrix, vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalize_data_storage(data_storage):\n",
    "    means = list()\n",
    "    stds = list()\n",
    "    for index in range(data_storage.shape[0]):\n",
    "        data = data_storage[index]\n",
    "        means.append(data.mean(axis=(1, 2, 3)))\n",
    "        stds.append(data.std(axis=(1, 2, 3)))\n",
    "    mean = np.asarray(means).mean(axis=0)\n",
    "    std = np.asarray(stds).mean(axis=0)\n",
    "    for index in range(data_storage.shape[0]):\n",
    "        data_storage[index] = normalize_data(data_storage[index], mean, std)\n",
    "    return data_storage\n",
    "\n",
    "def normalize_data(data, mean, std):\n",
    "    data -= mean[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    data /= std[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "import sys\n",
    "import collections\n",
    "import pydicom\n",
    "import scipy\n",
    "\n",
    "\n",
    "sys.path.insert(0,'C:/3DUnetCNN-master/unet3d/utils') \n",
    "\n",
    "try:\n",
    "    from .nilearn_custom_utils.nilearn_utils import crop_img_to\n",
    "    from .sitk_utils import resample_to_spacing, calculate_origin_offset\n",
    "except:\n",
    "    from nilearn_custom_utils.nilearn_utils import crop_img_to\n",
    "    from sitk_utils import resample_to_spacing, calculate_origin_offset   \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "#%matplotlib inline\n",
    "path = 'G:/CTimages/preprocessed/'\n",
    "\n",
    "all_scans = os.listdir(path)\n",
    "means = list()\n",
    "stds = list()\n",
    "normalized_list = list()\n",
    "\n",
    "\n",
    "image_shape = (64,64,64)\n",
    "\n",
    "label_indices=1\n",
    "if label_indices is None:\n",
    "    label_indices = []\n",
    "elif not isinstance(label_indices, collections.Iterable) or isinstance(label_indices, str):\n",
    "    label_indices = [label_indices]\n",
    "image_list = list()\n",
    "\n",
    "\n",
    "for index,file in enumerate(all_scans):\n",
    "    print(index)\n",
    "    data_file = os.path.join(path,file,file+'_ct.npy')\n",
    "    affine = os.path.join(path,file,file+'_affine.npy')#gives the exact path to \"predicition.nii.gz\" \n",
    "    previous_affine = np.load(affine)\n",
    "    header_path = 'G:/CTimages CT/original/'\n",
    "      \n",
    "    scan_path = header_path+file+'/'\n",
    "    first_scan = os.listdir(scan_path)[0]\n",
    "    scan = pydicom.dcmread(scan_path+first_scan)\n",
    "    data = np.load(data_file)\n",
    "    \n",
    "    if (label_indices is None and (index + 1) == len(image_files)) \\\n",
    "            or (label_indices is not None and index in label_indices):\n",
    "        interpolation = \"nearest\"\n",
    "    else:\n",
    "        interpolation = \"linear\"\n",
    "    data = fix_shape(data)\n",
    "    image, affine,spacing = resize(data,previous_affine, scan, new_shape=image_shape, interpolation=interpolation)\n",
    "    image_list.append(image)\n",
    "\n",
    "    \n",
    "    means.append(image.mean(axis=(1, 2)))\n",
    "    stds.append(data.std(axis=(1, 2)))\n",
    "mean = np.asarray(means).mean(axis=0)\n",
    "std = np.asarray(stds).mean(axis=0)\n",
    "for index in range(all_scans.shape[0]):\n",
    "    data_file = os.path.join(all_scans+file+'/'+file+'_ct.nii.gz')\n",
    "    data_image = nib.load(data_file)\n",
    "    data = data_image.get_data()\n",
    "    normalized_list.append(normalize_data(data, mean, std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
